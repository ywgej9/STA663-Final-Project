{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project (30%)\n",
    "\n",
    "For the final project, you will need to implement a \"new\" statistical algorithm in Python from the research literature and write a \"paper\" describing the algorithm. \n",
    "\n",
    "Deadline 2nd May 2018 at 11:59 PM\n",
    "\n",
    "Note: 1 bonus point for each day that it is submitted before the deadline. The actual project has a maximum grade of 100, but bonus points can push it above 100.\n",
    "\n",
    "## Paper\n",
    "\n",
    "The paper should have the following:\n",
    "\n",
    "### Title\n",
    "\n",
    "Should be consise and informative.\n",
    "\n",
    "### Abstract\n",
    "\n",
    "250 words or less. Identify 4-6 key phrases.\n",
    "\n",
    "### Background\n",
    "\n",
    "State the research paper you are using. Describe the concept of the algorithm and why it is interesting and/or useful. If appropriate, describe the mathematical basis of the algorithm. Some potential topics for the backgorund include:\n",
    "\n",
    "- What problem does it address? \n",
    "- What are known and possible applications of the algorithm? \n",
    "- What are its advantages and disadvantages relative to other algorithms?\n",
    "- How will you use it in your research?\n",
    "\n",
    "### Description of algorithm\n",
    "\n",
    "First, explain in plain English what the algorithm does. Then describes the details of the algorihtm, using mathematical equations or pseudocode as appropriate. \n",
    "\n",
    "### Describe optimization for performance\n",
    "\n",
    "First implement the algorithm using plain Python in a straightforward way from the description of the algorihtm. Then profile and optimize it using one or more apporpiate mathods, such as:\n",
    "\n",
    "1. Use of better algorithms or data structures\n",
    "2. Use of vectorization\n",
    "3. JIT or AOT compilation of critical functions\n",
    "4. Re-writing critical functions in C++ and using pybind11 to wrap them\n",
    "5. Making use of parallelism or concurrency\n",
    "6. Making use of distributed compuitng\n",
    "\n",
    "Document the improvemnt in performance with the optimizations performed.\n",
    "\n",
    "### Applications to simulated data sets\n",
    "\n",
    "Are there specific inputs that give known outuputs (e.g. there might be closed form solutions for special input cases)? How does the algorithm perform on these? \n",
    "\n",
    "If no such input cases are available (or in addition to such input cases), how does the algorithm perform on simulated data sets for which you know the \"truth\"? \n",
    "\n",
    "### Applications to real data sets\n",
    "\n",
    "Test the algorithm on the real-world examples in the orignal paper if possible. Try to find at least one other real-world data set not in the original paper and test it on that. Describe and interpret the results.\n",
    "\n",
    "### Comparative analysis with competing algorihtms\n",
    "\n",
    "Find two other algorihtms that addresss a similar problem. Perform a comparison - for example, of accurary or speed. You can use native libraires of the other algorithms - you do not need to code them yourself. Comment on your observations. \n",
    "\n",
    "### Discussion/conclusion\n",
    "\n",
    "Your thoughts on the algorithm. Does it fulfill a particular need? How could it be generalized to other problem domains? What are its limiations and how could it be improved further?\n",
    "\n",
    "### References/bibliography\n",
    "\n",
    "Make sure you cite your sources.\n",
    "\n",
    "## Code\n",
    "\n",
    "The code should be in a public GitHub repository with:\n",
    "\n",
    "1. A README file\n",
    "2. An open source license\n",
    "3. Source code\n",
    "4. Test code\n",
    "5. Examples\n",
    "6. A reproducible report\n",
    "\n",
    "The package should be downloadable and installable with `python setup.py install`, or even posted to PyPI adn installable with `pip install package`.\n",
    "\n",
    "\n",
    "## Rubric\n",
    "\n",
    "Each item is worth 10 points, but some sections will give up to 10 bonus points if done really well. Note that the \"difficulty factor\" of the chosen algorithm will be factored into the grading. \n",
    "\n",
    "1. Is the abstract, background and discussion readable and clear? (10-20 points)\n",
    "2. Is the algorithm description clear and accurate? (10-20 points)\n",
    "3. Has the algorihtm been optimized? (10-20 points)\n",
    "4. Are the applicaitons to simulated/real data clear and useful? (10-20 points)\n",
    "5. Was the comarative analysis done well? (10-20 points points)\n",
    "6. Is there a well-maitnatined Github repository for the code? (10 points)\n",
    "7. Is the document show evidenc of literate programming? (10 points)\n",
    "8. Is the analyiss reproducible? (10 points)\n",
    "9. Is the code tested? Are examples provided? (10 points)\n",
    "10. Is the package easily installable? (10 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hamiltonian Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Suppose U is given\n",
    "def U(x):\n",
    "    return -2*x**2 + x**4\n",
    "\n",
    "def grad_U(x):\n",
    "    return -4*x + 4*x**3\n",
    "\n",
    "def H(theta, r ,U, M_inv):\n",
    "    '''Hamiltonian function of total energy'''\n",
    "    return U(theta) + 0.5 * r.T @ M_inv @ r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose U is computed from given prior and xmodel\n",
    "\n",
    "# test: a normal prior, suppose to be given\n",
    "def prior(theta):\n",
    "    return scipy.stats.norm.pdf(theta)\n",
    "\n",
    "def xmodel(x, theta):\n",
    "    return scipy.stats.norm.pdf(x, loc = theta)\n",
    "\n",
    "def U(X, theta, xmodel, prior):\n",
    "    '''compute U from prior, xmodel, and data X'''\n",
    "    # X should be a vetor\n",
    "    temp = 0\n",
    "    for x in X:\n",
    "        temp += np.log(xmodel(x, theta))\n",
    "    return - temp - np.log(prior(theta))\n",
    "\n",
    "def grad_U(X, theta, xmodel, prior, h = 0.0001):\n",
    "    '''compute the gradient of U'''\n",
    "    d = theta.shape[0]\n",
    "    ans = []\n",
    "    u0 = U(X, theta, xmodel, prior)\n",
    "    for i in range(d):\n",
    "        theta0 = theta\n",
    "        theta0[i] += h\n",
    "        u1 = U(X, theta0, xmodel, prior)\n",
    "        print((u0, u1))\n",
    "        ans.append( (u1-u0)/h )\n",
    "    return ans\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 3.7568156]), array([ 3.7568156]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ -4.44089210e-08])]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1.],[2.]])\n",
    "theta = np.array([1.])\n",
    "grad_U(X, theta, xmodel, prior, h = 0.00000001) # this is sensitive to choice of h, check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hmc(theta_0, eps, niter, m, M, U, grad_U, prior, xmodel):\n",
    "    \"\"\"Hamiltonian Monte Carlo\"\"\"\n",
    "    d = theta_0.shape[0]\n",
    "    Theta = np.empty((d, niter))\n",
    "    R = np.empty((d, niter))\n",
    "    M_inv = scipy.linalg.inv(M)\n",
    "    theta = theta_0\n",
    "    for i in range(niter):\n",
    "        r = np.random.multivariate_normal(np.zeros(d), M, 1).flatten()      \n",
    "        theta_old = theta\n",
    "        r_old = r\n",
    "            \n",
    "        #discretize Hamiltonian dynamics\n",
    "        r -= eps / 2 * grad_U(theta)\n",
    "        for j in range(m):\n",
    "            theta += eps * M_inv @ r\n",
    "            r -= eps * grad_U(theta)  \n",
    "        r -= eps / 2 * grad_U(theta)\n",
    "        \n",
    "        #M-H correction\n",
    "        u = np.random.uniform(0, 1, 1)\n",
    "        rho = np.exp(H(theta, r ,U, M_inv)-H(theta_old, r_old ,U, M_inv))        \n",
    "        if u < rho:\n",
    "            Theta[:,i] = theta\n",
    "            R[:,i] = r\n",
    "        else:\n",
    "            Theta[:,i] = theta_old\n",
    "            R[:,i] = r_old\n",
    "        theta = Theta[:,i]\n",
    "        \n",
    "    return Theta, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This should be in the main function\n",
    "\n",
    "#user inputs:\n",
    "theta_0 = np.array([1.])\n",
    "eps = 0.01\n",
    "niter = 100\n",
    "M = np.array([1.]).reshape(1,1)\n",
    "m = 100\n",
    "\n",
    "Theta, R = hmc(theta_0, eps, niter, m, M, U, grad_U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sghmc(theta_0, eps, niter, m, M, U, grad_Uï¼Œperc, prior, xmodel):\n",
    "    \"\"\"Stochastic Gradient Hamiltonian Monte Carlo\"\"\"\n",
    "    # theta_0: the starting point\n",
    "    # eps: step length in solving the dynamic system\n",
    "    # niter: the number sampling\n",
    "    # m: the maximum number of steps to take for solving the Hamiltonian\n",
    "    # M: the mass matrix in the Hamiltonian\n",
    "    # perc: the percentage of minbatch size over total size\n",
    "    d = theta_0.shape[0]\n",
    "    batch_size = int(np.floor(X.shape[0] * perc))\n",
    "    Theta = np.empty((d, niter))\n",
    "    R = np.empty((d, niter))\n",
    "    M_inv_eps = scipy.linalg.inv(M) * eps\n",
    "    theta = theta_0\n",
    "    M0 = C @ M_inv_eps\n",
    "    V = 2*eps*(C - B_hat)\n",
    "    for i in range(niter):\n",
    "        r = np.random.multivariate_normal(np.zeros(d), M, 1).flatten()      \n",
    "        for j in range(m):\n",
    "            theta += M_inv_eps @ r           \n",
    "            X0 = X[np.random.randint(batch_size, size = (batch_size,)),] #sample X\n",
    "            r = r - eps * grad_U(X0, theta, xmodel, prior, h = 0.0001) - M0 @ r + np.random.multivariate_normal(np.zeros(d), V, 1)        \n",
    "        Theta[:,i] = theta\n",
    "        R[:,i] = r\n",
    "        \n",
    "    return Theta, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
